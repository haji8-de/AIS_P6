{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import koreanize_matplotlib\n",
    "\n",
    "import sklearn\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "import huggingface_hub\n",
    "import transformers\n",
    "import nltk\n",
    "import konlpy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ver. Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.15\n",
      "numpy : 1.23.4\n",
      "pandas : 1.4.2\n",
      "librosa :  0.8.0\n",
      "matplotlib :  3.6.2\n",
      "seaborn :  0.12.1\n",
      "sklearn :  1.0.2\n",
      "torch :  1.12.1\n",
      "TF :  2.6.0\n",
      "Huggingface :  0.13.1\n",
      "Transformers :  4.26.1\n",
      "nltk :  3.7\n",
      "konlpy :  0.6.0\n"
     ]
    }
   ],
   "source": [
    "# 버전 확인\n",
    "!python --version\n",
    "print(\"numpy :\", np.__version__)\n",
    "print(\"pandas :\", pd.__version__)\n",
    "print(\"librosa : \", librosa.__version__)\n",
    "print(\"matplotlib : \", matplotlib.__version__)\n",
    "print(\"seaborn : \", sns.__version__)\n",
    "print(\"sklearn : \", sklearn.__version__)\n",
    "print(\"torch : \", torch.__version__)\n",
    "print(\"TF : \", tf.__version__)\n",
    "print(\"Huggingface : \", huggingface_hub.__version__)\n",
    "print(\"Transformers : \", transformers.__version__)\n",
    "print(\"nltk : \", nltk.__version__)\n",
    "print(\"konlpy : \", konlpy.__version__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow (Keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 15386652245478787893,\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 14053015552\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 1582601319452143566\n",
       " physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 4080, pci bus id: 0000:01:00.0, compute capability: 8.9\"]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GPU 확인 - TF\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 3s 894us/step - loss: 0.2992 - accuracy: 0.9130\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 2s 864us/step - loss: 0.1456 - accuracy: 0.9566\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 2s 849us/step - loss: 0.1092 - accuracy: 0.9664\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 2s 961us/step - loss: 0.0895 - accuracy: 0.9720\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 2s 887us/step - loss: 0.0753 - accuracy: 0.9760\n",
      "313/313 - 0s - loss: 0.0813 - accuracy: 0.9767\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08129224181175232, 0.9767000079154968]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF GPU Use\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "with tf.device(\"/device:GPU:0\"):\n",
    "    model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CUDA'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GPU 확인 - torch\n",
    "\"CUDA\" if torch.cuda.is_available() else \"CPU\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 2179.24853515625\n",
      "199 1459.31982421875\n",
      "299 978.7913208007812\n",
      "399 657.8762817382812\n",
      "499 443.4300231933594\n",
      "599 300.0424499511719\n",
      "699 204.10565185546875\n",
      "799 139.8732452392578\n",
      "899 96.83787536621094\n",
      "999 67.98318481445312\n",
      "1099 48.62169647216797\n",
      "1199 35.61973571777344\n",
      "1299 26.881492614746094\n",
      "1399 21.003536224365234\n",
      "1499 17.04613494873047\n",
      "1599 14.37941837310791\n",
      "1699 12.580742835998535\n",
      "1799 11.366353988647461\n",
      "1899 10.545650482177734\n",
      "1999 9.990435600280762\n",
      "Result: y = -0.022755874320864677 + 0.8826627135276794 x + 0.003925764933228493 x^2 + -0.09701754152774811 x^3\n"
     ]
    }
   ],
   "source": [
    "# Torch GPU Use\n",
    "import math\n",
    "\n",
    "dtype = torch.float\n",
    "# device = torch.device(\"cpu\")\n",
    "device = torch.device(\"cuda\") # Uncomment this to run on GPU, GPU 를 사용하므로 해당 라인 실행\n",
    "\n",
    "# Create random input and output data\n",
    "x = torch.linspace(-math.pi, math.pi, 2000, device=device, dtype=dtype)\n",
    "y = torch.sin(x)\n",
    "\n",
    "# Randomly initialize weights\n",
    "a = torch.randn((), device=device, dtype=dtype)\n",
    "b = torch.randn((), device=device, dtype=dtype)\n",
    "c = torch.randn((), device=device, dtype=dtype)\n",
    "d = torch.randn((), device=device, dtype=dtype)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(2000):\n",
    "    # Forward pass: compute predicted y\n",
    "    y_pred = a + b * x + c * x ** 2 + d * x ** 3\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = (y_pred - y).pow(2).sum().item()\n",
    "    if t % 100 == 99:\n",
    "        print(t, loss)\n",
    "\n",
    "    # Backprop to compute gradients of a, b, c, d with respect to loss\n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    grad_a = grad_y_pred.sum()\n",
    "    grad_b = (grad_y_pred * x).sum()\n",
    "    grad_c = (grad_y_pred * x ** 2).sum()\n",
    "    grad_d = (grad_y_pred * x ** 3).sum()\n",
    "\n",
    "    # Update weights using gradient descent\n",
    "    a -= learning_rate * grad_a\n",
    "    b -= learning_rate * grad_b\n",
    "    c -= learning_rate * grad_c\n",
    "    d -= learning_rate * grad_d\n",
    "\n",
    "\n",
    "print(f'Result: y = {a.item()} + {b.item()} x + {c.item()} x^2 + {d.item()} x^3')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8777145f9df449f1891c8670dbab3933",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\spec3\\anaconda3\\envs\\NN\\lib\\site-packages\\huggingface_hub-0.13.1-py3.8.egg\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\spec3\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cef610bc695f4dfca9610538a4510d9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6a6004e3d4e4c14ac30d58c835e5124",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c49e6398555482db528797a7b9aa462",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9997795224189758}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hugging face and Transformers\n",
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "classifier(\"we are very happy to show you the 🤗 Transformers library.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n",
      "단어 토큰화1 : ['Do', \"n't\", 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name', ',', 'Mr.', 'Jone', \"'s\", 'Orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop', '.']\n"
     ]
    }
   ],
   "source": [
    "# nltk 구동 확인\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
    "\n",
    "nltk.download()\n",
    "\n",
    "print('단어 토큰화1 :',word_tokenize(\"Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop.\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KONLPY\n",
    "- JDK==11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\"JAVA_HOME\" in os.environ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "JVMNotFoundException",
     "evalue": "No JVM shared library file (jvm.dll) found. Try setting up the JAVA_HOME environment variable properly.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJVMNotFoundException\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkonlpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtag\u001b[39;00m \u001b[39mimport\u001b[39;00m Okt\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkonlpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtag\u001b[39;00m \u001b[39mimport\u001b[39;00m Kkma\n\u001b[1;32m----> 5\u001b[0m okt \u001b[39m=\u001b[39m Okt()\n\u001b[0;32m      6\u001b[0m kkma \u001b[39m=\u001b[39m Kkma()\n\u001b[0;32m      8\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mOKT 형태소 분석 :\u001b[39m\u001b[39m'\u001b[39m,okt\u001b[39m.\u001b[39mmorphs(\u001b[39m\"\u001b[39m\u001b[39m열심히 코딩한 당신, 연휴에는 여행을 가봐요\u001b[39m\u001b[39m\"\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\spec3\\anaconda3\\envs\\NN\\lib\\site-packages\\konlpy\\tag\\_okt.py:51\u001b[0m, in \u001b[0;36mOkt.__init__\u001b[1;34m(self, jvmpath, max_heap_size)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, jvmpath\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, max_heap_size\u001b[39m=\u001b[39m\u001b[39m1024\u001b[39m):\n\u001b[0;32m     50\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m jpype\u001b[39m.\u001b[39misJVMStarted():\n\u001b[1;32m---> 51\u001b[0m         jvm\u001b[39m.\u001b[39;49minit_jvm(jvmpath, max_heap_size)\n\u001b[0;32m     53\u001b[0m     oktJavaPackage \u001b[39m=\u001b[39m jpype\u001b[39m.\u001b[39mJPackage(\u001b[39m'\u001b[39m\u001b[39mkr.lucypark.okt\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     54\u001b[0m     OktInterfaceJavaClass \u001b[39m=\u001b[39m oktJavaPackage\u001b[39m.\u001b[39mOktInterface\n",
      "File \u001b[1;32mc:\\Users\\spec3\\anaconda3\\envs\\NN\\lib\\site-packages\\konlpy\\jvm.py:55\u001b[0m, in \u001b[0;36minit_jvm\u001b[1;34m(jvmpath, max_heap_size)\u001b[0m\n\u001b[0;32m     52\u001b[0m args \u001b[39m=\u001b[39m [javadir, os\u001b[39m.\u001b[39msep]\n\u001b[0;32m     53\u001b[0m classpath \u001b[39m=\u001b[39m [f\u001b[39m.\u001b[39mformat(\u001b[39m*\u001b[39margs) \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m folder_suffix]\n\u001b[1;32m---> 55\u001b[0m jvmpath \u001b[39m=\u001b[39m jvmpath \u001b[39mor\u001b[39;00m jpype\u001b[39m.\u001b[39;49mgetDefaultJVMPath()\n\u001b[0;32m     57\u001b[0m \u001b[39m# NOTE: Temporary patch for Issue #76. Erase when possible.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[39mif\u001b[39;00m sys\u001b[39m.\u001b[39mplatform \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mdarwin\u001b[39m\u001b[39m'\u001b[39m\\\n\u001b[0;32m     59\u001b[0m         \u001b[39mand\u001b[39;00m jvmpath\u001b[39m.\u001b[39mfind(\u001b[39m'\u001b[39m\u001b[39m1.8.0\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\\\n\u001b[0;32m     60\u001b[0m         \u001b[39mand\u001b[39;00m jvmpath\u001b[39m.\u001b[39mendswith(\u001b[39m'\u001b[39m\u001b[39mlibjvm.dylib\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\spec3\\anaconda3\\envs\\NN\\lib\\site-packages\\jpype\\_jvmfinder.py:74\u001b[0m, in \u001b[0;36mgetDefaultJVMPath\u001b[1;34m()\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     73\u001b[0m     finder \u001b[39m=\u001b[39m LinuxJVMFinder()\n\u001b[1;32m---> 74\u001b[0m \u001b[39mreturn\u001b[39;00m finder\u001b[39m.\u001b[39;49mget_jvm_path()\n",
      "File \u001b[1;32mc:\\Users\\spec3\\anaconda3\\envs\\NN\\lib\\site-packages\\jpype\\_jvmfinder.py:212\u001b[0m, in \u001b[0;36mJVMFinder.get_jvm_path\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[39mif\u001b[39;00m jvm_notsupport_ext \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     \u001b[39mraise\u001b[39;00m jvm_notsupport_ext\n\u001b[1;32m--> 212\u001b[0m \u001b[39mraise\u001b[39;00m JVMNotFoundException(\u001b[39m\"\u001b[39m\u001b[39mNo JVM shared library file (\u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    213\u001b[0m                            \u001b[39m\"\u001b[39m\u001b[39mfound. Try setting up the JAVA_HOME \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    214\u001b[0m                            \u001b[39m\"\u001b[39m\u001b[39menvironment variable properly.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    215\u001b[0m                            \u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_libfile))\n",
      "\u001b[1;31mJVMNotFoundException\u001b[0m: No JVM shared library file (jvm.dll) found. Try setting up the JAVA_HOME environment variable properly."
     ]
    }
   ],
   "source": [
    "# konlpy 구동 확인\n",
    "from konlpy.tag import Okt\n",
    "from konlpy.tag import Kkma\n",
    "\n",
    "okt = Okt()\n",
    "kkma = Kkma()\n",
    "\n",
    "print('OKT 형태소 분석 :',okt.morphs(\"열심히 코딩한 당신, 연휴에는 여행을 가봐요\"))\n",
    "print('OKT 품사 태깅 :',okt.pos(\"열심히 코딩한 당신, 연휴에는 여행을 가봐요\"))\n",
    "print('OKT 명사 추출 :',okt.nouns(\"열심히 코딩한 당신, 연휴에는 여행을 가봐요\")) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
